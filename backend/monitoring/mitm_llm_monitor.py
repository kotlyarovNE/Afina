#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ LLM API –∑–∞–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ mitmproxy
–ó–∞–ø—É—Å–∫: python backend/monitoring/mitm_llm_monitor.py
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:8081
"""

import json
import re
from datetime import datetime
from mitmproxy import http, ctx
from mitmproxy.tools.dump import DumpMaster
from mitmproxy.options import Options
from mitmproxy.tools.web.master import WebMaster


class LLMMonitor:
    def __init__(self):
        self.request_counter = 0
        self.llm_providers = {
            'openai': 'api.openai.com',
            'anthropic': 'api.anthropic.com',
            'google': 'generativelanguage.googleapis.com',
            'cohere': 'api.cohere.ai',
            'huggingface': 'api-inference.huggingface.co'
        }
        
    def is_llm_request(self, flow: http.HTTPFlow) -> tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å LLM API –≤—ã–∑–æ–≤–æ–º"""
        host = flow.request.pretty_host.lower()
        
        for provider, domain in self.llm_providers.items():
            if domain in host:
                return True, provider
        
        return False, ""
    
    def extract_request_data(self, flow: http.HTTPFlow) -> dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""
        try:
            request_data = {}
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            request_data['timestamp'] = datetime.now().isoformat()
            request_data['method'] = flow.request.method
            request_data['url'] = flow.request.pretty_url
            request_data['headers'] = dict(flow.request.headers)
            
            # –¢–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ (–µ—Å–ª–∏ JSON)
            if flow.request.content:
                try:
                    content = flow.request.content.decode('utf-8')
                    if flow.request.headers.get('content-type', '').startswith('application/json'):
                        request_data['body'] = json.loads(content)
                    else:
                        request_data['body'] = content
                except:
                    request_data['body'] = "<binary data>"
            
            return request_data
        except Exception as e:
            return {'error': f'Failed to parse request: {str(e)}'}
    
    def extract_response_data(self, flow: http.HTTPFlow) -> dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        try:
            response_data = {}
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            response_data['status_code'] = flow.response.status_code
            response_data['headers'] = dict(flow.response.headers)
            
            # –¢–µ–ª–æ –æ—Ç–≤–µ—Ç–∞
            if flow.response.content:
                try:
                    content = flow.response.content.decode('utf-8')
                    if flow.response.headers.get('content-type', '').startswith('application/json'):
                        response_data['body'] = json.loads(content)
                    else:
                        response_data['body'] = content
                except:
                    response_data['body'] = "<binary data>"
            
            return response_data
        except Exception as e:
            return {'error': f'Failed to parse response: {str(e)}'}
    
    def format_for_console(self, provider: str, request_data: dict, response_data: dict = None) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        self.request_counter += 1
        
        output = f"\n{'='*80}\n"
        output += f"ü§ñ LLM REQUEST #{self.request_counter} - {provider.upper()}\n"
        output += f"{'='*80}\n"
        output += f"üìÖ Time: {request_data.get('timestamp', 'unknown')}\n"
        output += f"üåê URL: {request_data.get('url', 'unknown')}\n"
        output += f"üìù Method: {request_data.get('method', 'unknown')}\n"
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ (—Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ)
        important_headers = ['authorization', 'content-type', 'user-agent']
        headers = request_data.get('headers', {})
        filtered_headers = {k: v for k, v in headers.items() if k.lower() in important_headers}
        if filtered_headers:
            output += f"üìã Headers: {json.dumps(filtered_headers, indent=2)}\n"
        
        # –¢–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
        body = request_data.get('body', {})
        if isinstance(body, dict):
            # –î–ª—è OpenAI API –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞–∂–Ω—ã–µ –ø–æ–ª—è
            if 'messages' in body:
                output += f"üí¨ Messages ({len(body['messages'])}):\n"
                for i, msg in enumerate(body['messages'][-3:]):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
                    role = msg.get('role', 'unknown')
                    content = msg.get('content', '')
                    content_preview = content[:200] + '...' if len(content) > 200 else content
                    output += f"   {i+1}. {role}: {content_preview}\n"
            
            if 'model' in body:
                output += f"üß† Model: {body['model']}\n"
            if 'temperature' in body:
                output += f"üå°Ô∏è  Temperature: {body['temperature']}\n"
            if 'max_tokens' in body:
                output += f"üìè Max tokens: {body['max_tokens']}\n"
        
        # –û—Ç–≤–µ—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if response_data:
            output += f"\n{'‚îÄ'*40} RESPONSE {'‚îÄ'*40}\n"
            output += f"üìä Status: {response_data.get('status_code', 'unknown')}\n"
            
            resp_body = response_data.get('body', {})
            if isinstance(resp_body, dict):
                # –î–ª—è OpenAI –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç –∏ —Ç–æ–∫–µ–Ω—ã
                if 'choices' in resp_body and resp_body['choices']:
                    choice = resp_body['choices'][0]
                    if 'message' in choice:
                        content = choice['message'].get('content', '')
                        content_preview = content[:300] + '...' if len(content) > 300 else content
                        output += f"üí≠ Response: {content_preview}\n"
                
                if 'usage' in resp_body:
                    usage = resp_body['usage']
                    output += f"üî¢ Tokens: {usage.get('total_tokens', 0)} "
                    output += f"(prompt: {usage.get('prompt_tokens', 0)}, "
                    output += f"completion: {usage.get('completion_tokens', 0)})\n"
        
        output += f"{'='*80}\n"
        return output

    def request(self, flow: http.HTTPFlow) -> None:
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        is_llm, provider = self.is_llm_request(flow)
        
        if is_llm:
            request_data = self.extract_request_data(flow)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ flow –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ response
            flow.llm_provider = provider
            flow.llm_request_data = request_data
            
            # –í—ã–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å
            print(self.format_for_console(provider, request_data))

    def response(self, flow: http.HTTPFlow) -> None:
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–≤–µ—Ç–æ–≤"""
        if hasattr(flow, 'llm_provider'):
            response_data = self.extract_response_data(flow)
            
            # –í—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –æ—Ç–≤–µ—Ç–æ–º
            print(self.format_for_console(
                flow.llm_provider, 
                flow.llm_request_data, 
                response_data
            ))


def start_monitoring():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    print("üöÄ –ó–∞–ø—É—Å–∫ LLM API –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")
    print("üì± –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:8081")
    print("üîç –§–∏–ª—å—Ç—Ä: –¢–æ–ª—å–∫–æ LLM API –∑–∞–ø—Ä–æ—Å—ã (OpenAI, Anthropic, Google, Cohere, HuggingFace)")
    print("‚ö†Ô∏è  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –∫–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç HTTP_PROXY=http://localhost:8080")
    print("=" * 80)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ mitmproxy
    opts = Options(
        listen_port=8080,        # –ü–æ—Ä—Ç –ø—Ä–æ–∫—Å–∏
        web_port=8081,           # –ü–æ—Ä—Ç –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        web_open_browser=False,  # –ù–µ –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        confdir="~/.mitmproxy",  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    )
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Ç–µ—Ä —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º
    master = WebMaster(opts)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—à –∞–¥–¥–æ–Ω
    monitor = LLMMonitor()
    master.addons.add(monitor)
    
    try:
        master.run()
    except KeyboardInterrupt:
        print("\nüõë –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


if __name__ == "__main__":
    start_monitoring()
